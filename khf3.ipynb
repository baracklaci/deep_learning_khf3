{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "\n",
    "#function responsible for loading the data and making the X, Y datasets\n",
    "#@nb_days meaning how many days forward do we want our prediction, e.g. nb_days = 1 meaning tomorrow\n",
    "#the function returns the proper expected output for the model to work on\n",
    "def load_data(nb_days = 1):\n",
    "    window = nb_days + 1\n",
    "    #I am using 2018 and 2019 budapest fall season data\n",
    "    dataset1 = np.loadtxt('budapest_2018_daily.csv', delimiter=\",\")\n",
    "    dataset2 = np.loadtxt('budapest_2019_daily.csv', delimiter=\",\")\n",
    "\n",
    "    dataset1_len = len(dataset1)\n",
    "    dataset2_len = len(dataset2)\n",
    "    \n",
    "    Y = np.empty(dataset1_len - window + dataset2_len - window)\n",
    "    \n",
    "    #calculating the 2018 expected results\n",
    "    for i in range(dataset1_len - window):\n",
    "        Y[i] = ((dataset1[i+window][0] + dataset1[i+window][1]) / 2)\n",
    "        \n",
    "    #calculating the 2019 expected results\n",
    "    for i in range(dataset2_len - window):\n",
    "        Y[i + dataset1_len - window] = ((dataset2[i+window][0] + dataset2[i+window][1]) / 2)\n",
    "    #print(Y)\n",
    "    \n",
    "    \n",
    "    X = np.empty((dataset1_len - window + dataset2_len - window, len(dataset1[0])*2))\n",
    "    \n",
    "    #calculating the 2018 input data\n",
    "    for i in range(dataset1_len - window):\n",
    "        X[i][0:len(dataset1[0])] = dataset1[i]\n",
    "        X[i][len(dataset1[0]):] = dataset1[i + 1]\n",
    "        \n",
    "    #calculating the 2019 input data\n",
    "    for i in range(dataset2_len - window):\n",
    "        X[i + dataset1_len - window][0:len(dataset2[0])] = dataset2[i]\n",
    "        X[i + dataset1_len - window][len(dataset2[0]):] = dataset2[i + 1]\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the datasets\n",
    "def shuffleXY(X, Y):\n",
    "    np.random.seed(123)\n",
    "\n",
    "    randperm = np.random.permutation(len(X))\n",
    "    X, Y = X[randperm], Y[randperm]\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into train, valid and test datasets\n",
    "def split_data():\n",
    "    nb_samples = len(X)\n",
    "    valid = 0.2\n",
    "    test = 0.1\n",
    "    X_train = X[0:(int)(nb_samples*(1-valid-test))]\n",
    "    X_valid = X[(int)(nb_samples*(1-valid-test)):(int)(nb_samples*(1-test))]\n",
    "    X_test = X[(int)(nb_samples*(1-test)):]\n",
    "\n",
    "    Y_train = Y[0:(int)(nb_samples*(1-valid-test))]\n",
    "    Y_valid = Y[(int)(nb_samples*(1-valid-test)):(int)(nb_samples*(1-test))]\n",
    "    Y_test = Y[(int)(nb_samples*(1-test)):]\n",
    "\n",
    "    print(len(X_train))\n",
    "    print(len(X_valid))\n",
    "    print(len(X_test))\n",
    "    print(X[0].shape)\n",
    "    \n",
    "    return (X_train, X_valid, X_test, Y_train, Y_valid, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.compat.v1 import set_random_seed\n",
    "from keras.models import load_model\n",
    "\n",
    "#making the neural network, its a simple fully connected network, with mse loss function\n",
    "#and Adam optimizer\n",
    "#I used early stopping to prevent overfitting and ModelCheckpoint to load back the best model\n",
    "def learn():\n",
    "    np.random.seed(123)\n",
    "    set_random_seed(125)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_shape=X[0].shape))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='Adam')\n",
    "\n",
    "    patience=20\n",
    "    early_stopping=EarlyStopping(patience=patience, verbose=1)\n",
    "\n",
    "    checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=1)\n",
    "\n",
    "    model.fit(X_train, Y_train, batch_size=8, epochs=150, verbose=1, validation_data=(X_valid, Y_valid), \n",
    "              shuffle=True, callbacks=[checkpointer, early_stopping])\n",
    "    \n",
    "    model = load_model('weights.hdf5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing out the Mean Squared Error for the test dataset\n",
    "def test_error(model):\n",
    "    preds=model.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    test_mse = mean_squared_error(Y_test,preds)\n",
    "    print(\"Test MSE: %f\" % (test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "35\n",
      "18\n",
      "(14,)\n",
      "Epoch 1/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 597.3494\n",
      "Epoch 00001: val_loss improved from inf to 209.67537, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 396.3845 - val_loss: 209.6754\n",
      "Epoch 2/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 236.9298\n",
      "Epoch 00002: val_loss improved from 209.67537 to 76.70982, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 142.9022 - val_loss: 76.7098\n",
      "Epoch 3/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 63.9154\n",
      "Epoch 00003: val_loss improved from 76.70982 to 48.11173, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 63.0545 - val_loss: 48.1117\n",
      "Epoch 4/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 61.7821\n",
      "Epoch 00004: val_loss improved from 48.11173 to 22.97309, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.4553 - val_loss: 22.9731\n",
      "Epoch 5/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 17.6085\n",
      "Epoch 00005: val_loss improved from 22.97309 to 11.76945, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.7601 - val_loss: 11.7694\n",
      "Epoch 6/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 22.6185\n",
      "Epoch 00006: val_loss improved from 11.76945 to 7.05499, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 11.7244 - val_loss: 7.0550\n",
      "Epoch 7/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 11.7932\n",
      "Epoch 00007: val_loss improved from 7.05499 to 5.92726, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.0579 - val_loss: 5.9273\n",
      "Epoch 8/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3.6690\n",
      "Epoch 00008: val_loss improved from 5.92726 to 5.65411, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.2405 - val_loss: 5.6541\n",
      "Epoch 9/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 5.2740\n",
      "Epoch 00009: val_loss did not improve from 5.65411\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.0788 - val_loss: 5.7563\n",
      "Epoch 10/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 18.8897\n",
      "Epoch 00010: val_loss improved from 5.65411 to 5.63281, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.9530 - val_loss: 5.6328\n",
      "Epoch 11/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 20.8485\n",
      "Epoch 00011: val_loss improved from 5.63281 to 5.53908, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.9125 - val_loss: 5.5391\n",
      "Epoch 12/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 8.7674\n",
      "Epoch 00012: val_loss improved from 5.53908 to 5.45294, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.7772 - val_loss: 5.4529\n",
      "Epoch 13/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.4263\n",
      "Epoch 00013: val_loss did not improve from 5.45294\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.7553 - val_loss: 5.7238\n",
      "Epoch 14/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 9.2158\n",
      "Epoch 00014: val_loss improved from 5.45294 to 5.38177, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6872 - val_loss: 5.3818\n",
      "Epoch 15/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 9.8259\n",
      "Epoch 00015: val_loss did not improve from 5.38177\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.7215 - val_loss: 5.7420\n",
      "Epoch 16/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 31.5840\n",
      "Epoch 00016: val_loss improved from 5.38177 to 5.37285, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6185 - val_loss: 5.3728\n",
      "Epoch 17/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 4.0672\n",
      "Epoch 00017: val_loss did not improve from 5.37285\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.7141 - val_loss: 5.4363\n",
      "Epoch 18/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 11.6438\n",
      "Epoch 00018: val_loss did not improve from 5.37285\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6922 - val_loss: 5.4754\n",
      "Epoch 19/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.1985\n",
      "Epoch 00019: val_loss improved from 5.37285 to 5.21815, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.4336 - val_loss: 5.2181\n",
      "Epoch 20/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.9220\n",
      "Epoch 00020: val_loss did not improve from 5.21815\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.4312 - val_loss: 5.6424\n",
      "Epoch 21/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 4.2142\n",
      "Epoch 00021: val_loss did not improve from 5.21815\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.3433 - val_loss: 5.2665\n",
      "Epoch 22/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.1661\n",
      "Epoch 00022: val_loss did not improve from 5.21815\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.1941 - val_loss: 5.6714\n",
      "Epoch 23/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 5.0243\n",
      "Epoch 00023: val_loss did not improve from 5.21815\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.1509 - val_loss: 5.3393\n",
      "Epoch 24/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 5.4917\n",
      "Epoch 00024: val_loss did not improve from 5.21815\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.1273 - val_loss: 5.2733\n",
      "Epoch 25/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 6.7708\n",
      "Epoch 00025: val_loss improved from 5.21815 to 5.14137, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.0801 - val_loss: 5.1414\n",
      "Epoch 26/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 5.6995\n",
      "Epoch 00026: val_loss did not improve from 5.14137\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.1911 - val_loss: 5.5750\n",
      "Epoch 27/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 15.4770\n",
      "Epoch 00027: val_loss improved from 5.14137 to 5.12045, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.3414 - val_loss: 5.1205\n",
      "Epoch 28/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 5.5873\n",
      "Epoch 00028: val_loss did not improve from 5.12045\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8643 - val_loss: 5.3874\n",
      "Epoch 29/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.9609\n",
      "Epoch 00029: val_loss did not improve from 5.12045\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.9195 - val_loss: 5.2860\n",
      "Epoch 30/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 9.0416\n",
      "Epoch 00030: val_loss did not improve from 5.12045\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8128 - val_loss: 5.3518\n",
      "Epoch 31/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 12.3705\n",
      "Epoch 00031: val_loss improved from 5.12045 to 5.11894, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.7861 - val_loss: 5.1189\n",
      "Epoch 32/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.9458\n",
      "Epoch 00032: val_loss did not improve from 5.11894\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.9099 - val_loss: 5.3340\n",
      "Epoch 33/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 11.4623\n",
      "Epoch 00033: val_loss did not improve from 5.11894\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7936 - val_loss: 5.2107\n",
      "Epoch 34/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.6424\n",
      "Epoch 00034: val_loss did not improve from 5.11894\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.9489 - val_loss: 5.3453\n",
      "Epoch 35/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.6434\n",
      "Epoch 00035: val_loss did not improve from 5.11894\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7669 - val_loss: 5.1683\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/16 [>.............................] - ETA: 0s - loss: 3.9456\n",
      "Epoch 00036: val_loss did not improve from 5.11894\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6539 - val_loss: 5.3061\n",
      "Epoch 37/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 6.1574\n",
      "Epoch 00037: val_loss did not improve from 5.11894\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.0105 - val_loss: 5.1499\n",
      "Epoch 38/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 5.8815\n",
      "Epoch 00038: val_loss improved from 5.11894 to 5.11131, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6893 - val_loss: 5.1113\n",
      "Epoch 39/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3.4424\n",
      "Epoch 00039: val_loss did not improve from 5.11131\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6118 - val_loss: 5.2115\n",
      "Epoch 40/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.9104\n",
      "Epoch 00040: val_loss did not improve from 5.11131\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.4562 - val_loss: 5.1904\n",
      "Epoch 41/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 1.9322\n",
      "Epoch 00041: val_loss did not improve from 5.11131\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5162 - val_loss: 5.2038\n",
      "Epoch 42/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3.8598\n",
      "Epoch 00042: val_loss did not improve from 5.11131\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.3947 - val_loss: 5.1704\n",
      "Epoch 43/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 8.8870\n",
      "Epoch 00043: val_loss did not improve from 5.11131\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5270 - val_loss: 5.3851\n",
      "Epoch 44/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 13.2039\n",
      "Epoch 00044: val_loss improved from 5.11131 to 5.07662, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.4814 - val_loss: 5.0766\n",
      "Epoch 45/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3.4165\n",
      "Epoch 00045: val_loss did not improve from 5.07662\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4788 - val_loss: 5.4543\n",
      "Epoch 46/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3.3940\n",
      "Epoch 00046: val_loss did not improve from 5.07662\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.4606 - val_loss: 5.1692\n",
      "Epoch 47/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.2732\n",
      "Epoch 00047: val_loss did not improve from 5.07662\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3826 - val_loss: 5.2378\n",
      "Epoch 48/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 7.2261\n",
      "Epoch 00048: val_loss did not improve from 5.07662\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.3918 - val_loss: 5.2996\n",
      "Epoch 49/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 12.2302\n",
      "Epoch 00049: val_loss did not improve from 5.07662\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.4933 - val_loss: 5.3504\n",
      "Epoch 50/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 11.6629\n",
      "Epoch 00050: val_loss did not improve from 5.07662\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2590 - val_loss: 5.3694\n",
      "Epoch 51/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 4.3171\n",
      "Epoch 00051: val_loss did not improve from 5.07662\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.2076 - val_loss: 5.1919\n",
      "Epoch 52/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 13.0884\n",
      "Epoch 00052: val_loss improved from 5.07662 to 4.96009, saving model to weights.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.1587 - val_loss: 4.9601\n",
      "Epoch 53/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 6.2755\n",
      "Epoch 00053: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2157 - val_loss: 5.2593\n",
      "Epoch 54/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 7.1679\n",
      "Epoch 00054: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3978 - val_loss: 5.1033\n",
      "Epoch 55/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 11.6904\n",
      "Epoch 00055: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8631 - val_loss: 5.6423\n",
      "Epoch 56/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 10.9456\n",
      "Epoch 00056: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.2914 - val_loss: 5.4155\n",
      "Epoch 57/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 13.8500\n",
      "Epoch 00057: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.0916 - val_loss: 5.0476\n",
      "Epoch 58/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 4.6218\n",
      "Epoch 00058: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.0138 - val_loss: 5.3490\n",
      "Epoch 59/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 1.3747\n",
      "Epoch 00059: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9310 - val_loss: 5.0529\n",
      "Epoch 60/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.9682\n",
      "Epoch 00060: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.1338 - val_loss: 5.2907\n",
      "Epoch 61/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 4.2415\n",
      "Epoch 00061: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0188 - val_loss: 5.0491\n",
      "Epoch 62/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 13.1297\n",
      "Epoch 00062: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0089 - val_loss: 5.1240\n",
      "Epoch 63/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.8124\n",
      "Epoch 00063: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1947 - val_loss: 6.1938\n",
      "Epoch 64/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 8.6421\n",
      "Epoch 00064: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1881 - val_loss: 5.1716\n",
      "Epoch 65/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 7.2934\n",
      "Epoch 00065: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9263 - val_loss: 5.8686\n",
      "Epoch 66/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 1.9289\n",
      "Epoch 00066: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.9380 - val_loss: 5.0524\n",
      "Epoch 67/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 1.7669\n",
      "Epoch 00067: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.8732 - val_loss: 5.2469\n",
      "Epoch 68/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3.9852\n",
      "Epoch 00068: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.8844 - val_loss: 5.9037\n",
      "Epoch 69/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 6.2599\n",
      "Epoch 00069: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.0789 - val_loss: 5.3249\n",
      "Epoch 70/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3.6414\n",
      "Epoch 00070: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.9229 - val_loss: 6.0802\n",
      "Epoch 71/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2.9644\n",
      "Epoch 00071: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9572 - val_loss: 5.0678\n",
      "Epoch 72/150\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 4.2791\n",
      "Epoch 00072: val_loss did not improve from 4.96009\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.2624 - val_loss: 5.2678\n",
      "Epoch 00072: early stopping\n",
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efdbc28e4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 7.170969\n"
     ]
    }
   ],
   "source": [
    "#nb_days meaning how many days forward do we want our prediction, e.g. nb_days = 1 meaning tomorrow\n",
    "X, Y = load_data(nb_days = 1)\n",
    "X, Y = shuffleXY(X, Y)\n",
    "X_train, X_valid, X_test, Y_train, Y_valid, Y_test = split_data()\n",
    "model_tomorrow = learn()\n",
    "test_error(model_tomorrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicton for tomorrow: 11.327475°C degree\n"
     ]
    }
   ],
   "source": [
    "#the datas are: day1 max_temperature, min_temperature, sunny_hours, \n",
    "#feel_like_tempereture, max_temperature, precipitation(mm), \n",
    "#number of day in fall e.g. 09.01 means 1, 09.03 means 3, 10.01 means 32\n",
    "#and day2 with same datas\n",
    "test_array = np.asarray([18, 11, 7.1, 11, 18, 0, 58, 15, 8, 0, 5.2, 15, 0, 59]).reshape(1, -1)\n",
    "print(\"The predicton for tomorrow: \" + str(model_tomorrow.predict([test_array])[0][0]) + \"°C degree\")\n",
    "#this is for 28th of october"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "33\n",
      "17\n",
      "(14,)\n",
      "Epoch 1/150\n",
      " 2/15 [===>..........................] - ETA: 0s - loss: 478.6639WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0789s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 265.69254, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 383.2625 - val_loss: 265.6925\n",
      "Epoch 2/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 169.3785\n",
      "Epoch 00002: val_loss improved from 265.69254 to 97.70886, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 149.5923 - val_loss: 97.7089\n",
      "Epoch 3/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 32.4063\n",
      "Epoch 00003: val_loss improved from 97.70886 to 73.80709, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 68.2655 - val_loss: 73.8071\n",
      "Epoch 4/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 165.1502\n",
      "Epoch 00004: val_loss improved from 73.80709 to 49.36137, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 55.1175 - val_loss: 49.3614\n",
      "Epoch 5/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 40.9992\n",
      "Epoch 00005: val_loss improved from 49.36137 to 36.13688, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 40.3122 - val_loss: 36.1369\n",
      "Epoch 6/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 37.1112\n",
      "Epoch 00006: val_loss improved from 36.13688 to 27.96544, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 33.7604 - val_loss: 27.9654\n",
      "Epoch 7/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 33.9787\n",
      "Epoch 00007: val_loss improved from 27.96544 to 23.65037, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 29.9771 - val_loss: 23.6504\n",
      "Epoch 8/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 16.2163\n",
      "Epoch 00008: val_loss improved from 23.65037 to 21.17543, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 27.9425 - val_loss: 21.1754\n",
      "Epoch 9/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 19.5371\n",
      "Epoch 00009: val_loss improved from 21.17543 to 20.47079, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 27.6938 - val_loss: 20.4708\n",
      "Epoch 10/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 24.2342\n",
      "Epoch 00010: val_loss did not improve from 20.47079\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 26.7971 - val_loss: 21.2994\n",
      "Epoch 11/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 35.9562\n",
      "Epoch 00011: val_loss did not improve from 20.47079\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 27.2529 - val_loss: 20.8298\n",
      "Epoch 12/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 19.4360\n",
      "Epoch 00012: val_loss did not improve from 20.47079\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 26.8032 - val_loss: 22.3295\n",
      "Epoch 13/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 24.1133\n",
      "Epoch 00013: val_loss improved from 20.47079 to 20.39148, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 26.1080 - val_loss: 20.3915\n",
      "Epoch 14/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 21.7773\n",
      "Epoch 00014: val_loss did not improve from 20.39148\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 25.5129 - val_loss: 20.9434\n",
      "Epoch 15/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 18.1551\n",
      "Epoch 00015: val_loss did not improve from 20.39148\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 25.2065 - val_loss: 21.2186\n",
      "Epoch 16/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 13.5578\n",
      "Epoch 00016: val_loss did not improve from 20.39148\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 25.8160 - val_loss: 22.4078\n",
      "Epoch 17/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 10.6576\n",
      "Epoch 00017: val_loss improved from 20.39148 to 20.35983, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 24.4051 - val_loss: 20.3598\n",
      "Epoch 18/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 30.6247\n",
      "Epoch 00018: val_loss did not improve from 20.35983\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 24.5091 - val_loss: 21.3325\n",
      "Epoch 19/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 24.3225\n",
      "Epoch 00019: val_loss did not improve from 20.35983\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 24.3175 - val_loss: 20.6540\n",
      "Epoch 20/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 14.7321\n",
      "Epoch 00020: val_loss improved from 20.35983 to 20.14436, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 23.8748 - val_loss: 20.1444\n",
      "Epoch 21/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 31.1460\n",
      "Epoch 00021: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 23.8914 - val_loss: 21.3963\n",
      "Epoch 22/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 29.9701\n",
      "Epoch 00022: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 23.3868 - val_loss: 20.6372\n",
      "Epoch 23/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 26.2922\n",
      "Epoch 00023: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 23.3801 - val_loss: 21.6120\n",
      "Epoch 24/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 10.2203\n",
      "Epoch 00024: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 23.1999 - val_loss: 20.5409\n",
      "Epoch 25/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 35.1064\n",
      "Epoch 00025: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 23.0816 - val_loss: 20.6926\n",
      "Epoch 26/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 21.9780\n",
      "Epoch 00026: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 23.2494 - val_loss: 21.5270\n",
      "Epoch 27/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 9.2439\n",
      "Epoch 00027: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 23.1046 - val_loss: 20.3531\n",
      "Epoch 28/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 17.7699\n",
      "Epoch 00028: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 22.8586 - val_loss: 21.6116\n",
      "Epoch 29/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 24.9893\n",
      "Epoch 00029: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 22.5467 - val_loss: 20.7272\n",
      "Epoch 30/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 19.6579\n",
      "Epoch 00030: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 22.5710 - val_loss: 20.5830\n",
      "Epoch 31/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 20.2866\n",
      "Epoch 00031: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 21.9648 - val_loss: 22.0801\n",
      "Epoch 32/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 22.7596\n",
      "Epoch 00032: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 22.2148 - val_loss: 20.3834\n",
      "Epoch 33/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 22.6737\n",
      "Epoch 00033: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 22.8136 - val_loss: 20.2638\n",
      "Epoch 34/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 35.3356\n",
      "Epoch 00034: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 22.1235 - val_loss: 20.5251\n",
      "Epoch 35/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 27.1882\n",
      "Epoch 00035: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 23.5106 - val_loss: 20.2615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 37.3002\n",
      "Epoch 00036: val_loss did not improve from 20.14436\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 22.0908 - val_loss: 21.8408\n",
      "Epoch 37/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 39.9487\n",
      "Epoch 00037: val_loss improved from 20.14436 to 19.64133, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 21.7990 - val_loss: 19.6413\n",
      "Epoch 38/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 19.8927\n",
      "Epoch 00038: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 21.4489 - val_loss: 20.5452\n",
      "Epoch 39/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 13.5800\n",
      "Epoch 00039: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 21.0227 - val_loss: 20.1665\n",
      "Epoch 40/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 6.0235\n",
      "Epoch 00040: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 21.0837 - val_loss: 21.1474\n",
      "Epoch 41/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 26.1176\n",
      "Epoch 00041: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 21.2013 - val_loss: 19.8348\n",
      "Epoch 42/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 16.3936\n",
      "Epoch 00042: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 21.4964 - val_loss: 21.2819\n",
      "Epoch 43/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 22.5167\n",
      "Epoch 00043: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 20.9767 - val_loss: 20.0760\n",
      "Epoch 44/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 26.6613\n",
      "Epoch 00044: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 20.9173 - val_loss: 20.5844\n",
      "Epoch 45/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 21.1281\n",
      "Epoch 00045: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 21.4731 - val_loss: 20.9577\n",
      "Epoch 46/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 21.5884\n",
      "Epoch 00046: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 21.1226 - val_loss: 20.1197\n",
      "Epoch 47/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 13.6499\n",
      "Epoch 00047: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 19.9686 - val_loss: 20.2790\n",
      "Epoch 48/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 31.0383\n",
      "Epoch 00048: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 20.5960 - val_loss: 20.4258\n",
      "Epoch 49/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 15.7217\n",
      "Epoch 00049: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 19.8317 - val_loss: 19.7015\n",
      "Epoch 50/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 28.6786\n",
      "Epoch 00050: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 19.8070 - val_loss: 21.1361\n",
      "Epoch 51/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 22.9921\n",
      "Epoch 00051: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 19.5117 - val_loss: 20.5285\n",
      "Epoch 52/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 19.5433\n",
      "Epoch 00052: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 19.7222 - val_loss: 20.0401\n",
      "Epoch 53/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 18.0019\n",
      "Epoch 00053: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 20.1768 - val_loss: 21.4142\n",
      "Epoch 54/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 32.5960\n",
      "Epoch 00054: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 19.9216 - val_loss: 19.7055\n",
      "Epoch 55/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 7.2641\n",
      "Epoch 00055: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 19.0948 - val_loss: 20.5676\n",
      "Epoch 56/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 19.6236\n",
      "Epoch 00056: val_loss did not improve from 19.64133\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 19.0987 - val_loss: 19.7100\n",
      "Epoch 57/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 12.4446\n",
      "Epoch 00057: val_loss improved from 19.64133 to 19.59274, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 19.2244 - val_loss: 19.5927\n",
      "Epoch 58/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 11.2838\n",
      "Epoch 00058: val_loss did not improve from 19.59274\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 18.8188 - val_loss: 20.1590\n",
      "Epoch 59/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 30.2619\n",
      "Epoch 00059: val_loss did not improve from 19.59274\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 18.8641 - val_loss: 19.7513\n",
      "Epoch 60/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 12.2708\n",
      "Epoch 00060: val_loss improved from 19.59274 to 19.43345, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 18.6816 - val_loss: 19.4335\n",
      "Epoch 61/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 12.7543\n",
      "Epoch 00061: val_loss improved from 19.43345 to 19.32763, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 18.5920 - val_loss: 19.3276\n",
      "Epoch 62/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 28.6392\n",
      "Epoch 00062: val_loss did not improve from 19.32763\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 18.6718 - val_loss: 19.9178\n",
      "Epoch 63/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 26.4074\n",
      "Epoch 00063: val_loss did not improve from 19.32763\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 18.6122 - val_loss: 19.4745\n",
      "Epoch 64/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 21.5651\n",
      "Epoch 00064: val_loss did not improve from 19.32763\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 18.3028 - val_loss: 20.4265\n",
      "Epoch 65/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 13.7162\n",
      "Epoch 00065: val_loss did not improve from 19.32763\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 18.2064 - val_loss: 19.5768\n",
      "Epoch 66/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 22.8170\n",
      "Epoch 00066: val_loss did not improve from 19.32763\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 18.4361 - val_loss: 20.1051\n",
      "Epoch 67/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 18.2607\n",
      "Epoch 00067: val_loss did not improve from 19.32763\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 18.3959 - val_loss: 19.8434\n",
      "Epoch 68/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 11.2257\n",
      "Epoch 00068: val_loss did not improve from 19.32763\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 18.7134 - val_loss: 19.9919\n",
      "Epoch 69/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 23.8753\n",
      "Epoch 00069: val_loss did not improve from 19.32763\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 18.5651 - val_loss: 19.8096\n",
      "Epoch 70/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 9.0929\n",
      "Epoch 00070: val_loss improved from 19.32763 to 18.72513, saving model to weights.hdf5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 19.0066 - val_loss: 18.7251\n",
      "Epoch 71/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 15.6559\n",
      "Epoch 00071: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.7318 - val_loss: 20.2309\n",
      "Epoch 72/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 20.8343\n",
      "Epoch 00072: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 18.0488 - val_loss: 19.3731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 13.4972\n",
      "Epoch 00073: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.5867 - val_loss: 19.5509\n",
      "Epoch 74/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 23.0997\n",
      "Epoch 00074: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.6847 - val_loss: 19.7050\n",
      "Epoch 75/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 19.1961\n",
      "Epoch 00075: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.6661 - val_loss: 19.8603\n",
      "Epoch 76/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 14.8490\n",
      "Epoch 00076: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 18.0264 - val_loss: 20.5940\n",
      "Epoch 77/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 27.9310\n",
      "Epoch 00077: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.3862 - val_loss: 20.3023\n",
      "Epoch 78/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 5.6364\n",
      "Epoch 00078: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.4752 - val_loss: 19.2923\n",
      "Epoch 79/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 30.9102\n",
      "Epoch 00079: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.2015 - val_loss: 20.0995\n",
      "Epoch 80/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 15.1720\n",
      "Epoch 00080: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.2400 - val_loss: 20.6840\n",
      "Epoch 81/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 22.6468\n",
      "Epoch 00081: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.2225 - val_loss: 19.3844\n",
      "Epoch 82/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 17.3780\n",
      "Epoch 00082: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.1091 - val_loss: 19.9534\n",
      "Epoch 83/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 17.1747\n",
      "Epoch 00083: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 16.9642 - val_loss: 20.1450\n",
      "Epoch 84/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 21.2166\n",
      "Epoch 00084: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.2217 - val_loss: 19.6636\n",
      "Epoch 85/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 11.9735\n",
      "Epoch 00085: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 16.7960 - val_loss: 19.9308\n",
      "Epoch 86/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 14.8064\n",
      "Epoch 00086: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 16.8714 - val_loss: 19.8168\n",
      "Epoch 87/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 18.2071\n",
      "Epoch 00087: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 17.1779 - val_loss: 19.0716\n",
      "Epoch 88/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 30.9895\n",
      "Epoch 00088: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 16.7299 - val_loss: 19.0508\n",
      "Epoch 89/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 13.5850\n",
      "Epoch 00089: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 16.7177 - val_loss: 20.3149\n",
      "Epoch 90/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 8.1360\n",
      "Epoch 00090: val_loss did not improve from 18.72513\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 16.8250 - val_loss: 19.9607\n",
      "Epoch 00090: early stopping\n",
      "Test MSE: 13.964004\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data(nb_days = 7)\n",
    "X, Y = shuffleXY(X, Y)\n",
    "X_train, X_valid, X_test, Y_train, Y_valid, Y_test = split_data()\n",
    "model_week_forward = learn()\n",
    "test_error(model_week_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicton for a week forward: 8.846021°C degree\n"
     ]
    }
   ],
   "source": [
    "test_array = np.asarray([18, 11, 7.1, 11, 18, 0, 58, 15, 8, 0, 5.2, 15, 0, 59]).reshape(1, -1)\n",
    "print(\"The predicton for a week forward: \" + str(model_week_forward.predict([test_array])[0][0]) + \"°C degree\")\n",
    "#this is for 3rd of november"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "24\n",
      "13\n",
      "(14,)\n",
      "Epoch 1/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 404.2464WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0384s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 265.38562, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356.5075 - val_loss: 265.3856\n",
      "Epoch 2/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 311.9648\n",
      "Epoch 00002: val_loss improved from 265.38562 to 103.05072, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 224.9948 - val_loss: 103.0507\n",
      "Epoch 3/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 105.8429\n",
      "Epoch 00003: val_loss improved from 103.05072 to 49.26326, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 79.3339 - val_loss: 49.2633\n",
      "Epoch 4/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 30.6740\n",
      "Epoch 00004: val_loss did not improve from 49.26326\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.0174 - val_loss: 52.2707\n",
      "Epoch 5/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 22.6017\n",
      "Epoch 00005: val_loss improved from 49.26326 to 43.39244, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1789 - val_loss: 43.3924\n",
      "Epoch 6/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 61.0176\n",
      "Epoch 00006: val_loss improved from 43.39244 to 30.66170, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1813 - val_loss: 30.6617\n",
      "Epoch 7/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 19.8088\n",
      "Epoch 00007: val_loss improved from 30.66170 to 25.61581, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3230 - val_loss: 25.6158\n",
      "Epoch 8/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 23.3471\n",
      "Epoch 00008: val_loss improved from 25.61581 to 24.06229, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2081 - val_loss: 24.0623\n",
      "Epoch 9/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 21.8224\n",
      "Epoch 00009: val_loss improved from 24.06229 to 21.53193, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1542 - val_loss: 21.5319\n",
      "Epoch 10/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 13.1688\n",
      "Epoch 00010: val_loss improved from 21.53193 to 20.84994, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23.2721 - val_loss: 20.8499\n",
      "Epoch 11/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 26.3210\n",
      "Epoch 00011: val_loss improved from 20.84994 to 19.25818, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5097 - val_loss: 19.2582\n",
      "Epoch 12/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 14.0438\n",
      "Epoch 00012: val_loss improved from 19.25818 to 18.37266, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1077 - val_loss: 18.3727\n",
      "Epoch 13/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 8.3664\n",
      "Epoch 00013: val_loss improved from 18.37266 to 18.21162, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7599 - val_loss: 18.2116\n",
      "Epoch 14/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 1.6581\n",
      "Epoch 00014: val_loss improved from 18.21162 to 17.40259, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5341 - val_loss: 17.4026\n",
      "Epoch 15/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.8058\n",
      "Epoch 00015: val_loss improved from 17.40259 to 16.88058, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 21.0095 - val_loss: 16.8806\n",
      "Epoch 16/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 21.3134\n",
      "Epoch 00016: val_loss improved from 16.88058 to 16.71305, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.7124 - val_loss: 16.7130\n",
      "Epoch 17/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.5896\n",
      "Epoch 00017: val_loss improved from 16.71305 to 16.23202, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.4965 - val_loss: 16.2320\n",
      "Epoch 18/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 18.7710\n",
      "Epoch 00018: val_loss did not improve from 16.23202\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5046 - val_loss: 16.7852\n",
      "Epoch 19/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 27.3789\n",
      "Epoch 00019: val_loss improved from 16.23202 to 15.80173, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.0400 - val_loss: 15.8017\n",
      "Epoch 20/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 13.8959\n",
      "Epoch 00020: val_loss did not improve from 15.80173\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.8935 - val_loss: 15.8360\n",
      "Epoch 21/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 22.1878\n",
      "Epoch 00021: val_loss improved from 15.80173 to 15.45478, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.6890 - val_loss: 15.4548\n",
      "Epoch 22/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 36.0075\n",
      "Epoch 00022: val_loss improved from 15.45478 to 15.44988, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4786 - val_loss: 15.4499\n",
      "Epoch 23/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 31.9712\n",
      "Epoch 00023: val_loss improved from 15.44988 to 15.21920, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4673 - val_loss: 15.2192\n",
      "Epoch 24/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.1945\n",
      "Epoch 00024: val_loss did not improve from 15.21920\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.1839 - val_loss: 15.3873\n",
      "Epoch 25/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 24.8471\n",
      "Epoch 00025: val_loss improved from 15.21920 to 15.09684, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.0167 - val_loss: 15.0968\n",
      "Epoch 26/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 31.9177\n",
      "Epoch 00026: val_loss improved from 15.09684 to 15.09581, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9961 - val_loss: 15.0958\n",
      "Epoch 27/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 15.2878\n",
      "Epoch 00027: val_loss improved from 15.09581 to 14.44175, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.7862 - val_loss: 14.4418\n",
      "Epoch 28/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 21.5969\n",
      "Epoch 00028: val_loss improved from 14.44175 to 14.38532, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.6966 - val_loss: 14.3853\n",
      "Epoch 29/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 21.9029\n",
      "Epoch 00029: val_loss did not improve from 14.38532\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.8848 - val_loss: 14.9637\n",
      "Epoch 30/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 19.5291\n",
      "Epoch 00030: val_loss improved from 14.38532 to 14.24763, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.4070 - val_loss: 14.2476\n",
      "Epoch 31/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 22.5063\n",
      "Epoch 00031: val_loss improved from 14.24763 to 14.21524, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.2964 - val_loss: 14.2152\n",
      "Epoch 32/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 8.1021\n",
      "Epoch 00032: val_loss did not improve from 14.21524\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.5380 - val_loss: 14.8142\n",
      "Epoch 33/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 22.5591\n",
      "Epoch 00033: val_loss improved from 14.21524 to 13.99224, saving model to weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 17.7900 - val_loss: 13.9922\n",
      "Epoch 34/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 23.9933\n",
      "Epoch 00034: val_loss improved from 13.99224 to 13.91194, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.8302 - val_loss: 13.9119\n",
      "Epoch 35/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.6200\n",
      "Epoch 00035: val_loss did not improve from 13.91194\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 17.5865 - val_loss: 13.9271\n",
      "Epoch 36/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 15.9669\n",
      "Epoch 00036: val_loss did not improve from 13.91194\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 17.7001 - val_loss: 13.9657\n",
      "Epoch 37/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 26.4769\n",
      "Epoch 00037: val_loss improved from 13.91194 to 13.42880, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.4243 - val_loss: 13.4288\n",
      "Epoch 38/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 16.7033\n",
      "Epoch 00038: val_loss did not improve from 13.42880\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 17.5226 - val_loss: 13.5096\n",
      "Epoch 39/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.3323\n",
      "Epoch 00039: val_loss did not improve from 13.42880\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 17.6022 - val_loss: 14.2427\n",
      "Epoch 40/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 25.3439\n",
      "Epoch 00040: val_loss improved from 13.42880 to 13.25949, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 17.0839 - val_loss: 13.2595\n",
      "Epoch 41/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.4032\n",
      "Epoch 00041: val_loss improved from 13.25949 to 13.11577, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 17.2191 - val_loss: 13.1158\n",
      "Epoch 42/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 44.2929\n",
      "Epoch 00042: val_loss did not improve from 13.11577\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 17.7290 - val_loss: 13.7686\n",
      "Epoch 43/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 23.2671\n",
      "Epoch 00043: val_loss improved from 13.11577 to 13.05120, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.7394 - val_loss: 13.0512\n",
      "Epoch 44/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 10.7619\n",
      "Epoch 00044: val_loss did not improve from 13.05120\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 16.7091 - val_loss: 13.1241\n",
      "Epoch 45/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 3.9415\n",
      "Epoch 00045: val_loss did not improve from 13.05120\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 16.4344 - val_loss: 13.2293\n",
      "Epoch 46/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 15.4748\n",
      "Epoch 00046: val_loss improved from 13.05120 to 12.98942, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.3192 - val_loss: 12.9894\n",
      "Epoch 47/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 23.7667\n",
      "Epoch 00047: val_loss improved from 12.98942 to 12.92828, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.2607 - val_loss: 12.9283\n",
      "Epoch 48/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 13.2049\n",
      "Epoch 00048: val_loss improved from 12.92828 to 12.54878, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.1521 - val_loss: 12.5488\n",
      "Epoch 49/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 25.9283\n",
      "Epoch 00049: val_loss did not improve from 12.54878\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 16.2975 - val_loss: 12.7689\n",
      "Epoch 50/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 25.8308\n",
      "Epoch 00050: val_loss did not improve from 12.54878\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.9701 - val_loss: 12.5786\n",
      "Epoch 51/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 3.2673\n",
      "Epoch 00051: val_loss improved from 12.54878 to 12.30766, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.8408 - val_loss: 12.3077\n",
      "Epoch 52/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 13.5015\n",
      "Epoch 00052: val_loss improved from 12.30766 to 12.29712, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.0228 - val_loss: 12.2971\n",
      "Epoch 53/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 5.7044\n",
      "Epoch 00053: val_loss improved from 12.29712 to 12.08410, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.9800 - val_loss: 12.0841\n",
      "Epoch 54/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.6783\n",
      "Epoch 00054: val_loss did not improve from 12.08410\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.6071 - val_loss: 12.3851\n",
      "Epoch 55/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 28.2868\n",
      "Epoch 00055: val_loss did not improve from 12.08410\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.7284 - val_loss: 12.0907\n",
      "Epoch 56/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.7921\n",
      "Epoch 00056: val_loss did not improve from 12.08410\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.5477 - val_loss: 12.1348\n",
      "Epoch 57/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.9150\n",
      "Epoch 00057: val_loss did not improve from 12.08410\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.8276 - val_loss: 12.5740\n",
      "Epoch 58/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 10.3203\n",
      "Epoch 00058: val_loss improved from 12.08410 to 11.97430, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.1719 - val_loss: 11.9743\n",
      "Epoch 59/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 8.5125\n",
      "Epoch 00059: val_loss improved from 11.97430 to 11.75994, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.4263 - val_loss: 11.7599\n",
      "Epoch 60/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 13.9056\n",
      "Epoch 00060: val_loss did not improve from 11.75994\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.1538 - val_loss: 12.0899\n",
      "Epoch 61/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 19.7626\n",
      "Epoch 00061: val_loss improved from 11.75994 to 11.59968, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.2250 - val_loss: 11.5997\n",
      "Epoch 62/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.0359\n",
      "Epoch 00062: val_loss did not improve from 11.59968\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.0865 - val_loss: 11.7467\n",
      "Epoch 63/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 29.1909\n",
      "Epoch 00063: val_loss did not improve from 11.59968\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.1666 - val_loss: 12.0375\n",
      "Epoch 64/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.1764\n",
      "Epoch 00064: val_loss did not improve from 11.59968\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.8745 - val_loss: 11.6573\n",
      "Epoch 65/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 5.9919\n",
      "Epoch 00065: val_loss improved from 11.59968 to 11.36961, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.8890 - val_loss: 11.3696\n",
      "Epoch 66/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 28.1530\n",
      "Epoch 00066: val_loss did not improve from 11.36961\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.9420 - val_loss: 11.6066\n",
      "Epoch 67/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 18.4892\n",
      "Epoch 00067: val_loss did not improve from 11.36961\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.8316 - val_loss: 11.4873\n",
      "Epoch 68/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 10.0603\n",
      "Epoch 00068: val_loss did not improve from 11.36961\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.8019 - val_loss: 11.7766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 19.6362\n",
      "Epoch 00069: val_loss did not improve from 11.36961\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.7308 - val_loss: 11.3792\n",
      "Epoch 70/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.9891\n",
      "Epoch 00070: val_loss improved from 11.36961 to 11.34611, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.9457 - val_loss: 11.3461\n",
      "Epoch 71/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 22.7161\n",
      "Epoch 00071: val_loss did not improve from 11.34611\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.7769 - val_loss: 11.8829\n",
      "Epoch 72/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 20.8947\n",
      "Epoch 00072: val_loss improved from 11.34611 to 11.16740, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.7185 - val_loss: 11.1674\n",
      "Epoch 73/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 14.1124\n",
      "Epoch 00073: val_loss did not improve from 11.16740\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.4428 - val_loss: 11.5870\n",
      "Epoch 74/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 24.3159\n",
      "Epoch 00074: val_loss did not improve from 11.16740\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.3713 - val_loss: 11.7410\n",
      "Epoch 75/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 12.0629\n",
      "Epoch 00075: val_loss did not improve from 11.16740\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.3455 - val_loss: 11.5033\n",
      "Epoch 76/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 15.8975\n",
      "Epoch 00076: val_loss improved from 11.16740 to 11.13514, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.2868 - val_loss: 11.1351\n",
      "Epoch 77/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.7378\n",
      "Epoch 00077: val_loss did not improve from 11.13514\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.2189 - val_loss: 11.4274\n",
      "Epoch 78/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 18.5683\n",
      "Epoch 00078: val_loss did not improve from 11.13514\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.1194 - val_loss: 11.3915\n",
      "Epoch 79/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 5.5459\n",
      "Epoch 00079: val_loss did not improve from 11.13514\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.1473 - val_loss: 11.3031\n",
      "Epoch 80/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 6.7145\n",
      "Epoch 00080: val_loss did not improve from 11.13514\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.1825 - val_loss: 11.7131\n",
      "Epoch 81/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 24.0456\n",
      "Epoch 00081: val_loss did not improve from 11.13514\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.0315 - val_loss: 11.4169\n",
      "Epoch 82/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 12.2048\n",
      "Epoch 00082: val_loss improved from 11.13514 to 11.02141, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.4673 - val_loss: 11.0214\n",
      "Epoch 83/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 23.7666\n",
      "Epoch 00083: val_loss did not improve from 11.02141\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.1660 - val_loss: 11.7843\n",
      "Epoch 84/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 10.4632\n",
      "Epoch 00084: val_loss did not improve from 11.02141\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.9215 - val_loss: 11.2967\n",
      "Epoch 85/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 3.8808\n",
      "Epoch 00085: val_loss improved from 11.02141 to 10.87925, saving model to weights.hdf5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.0814 - val_loss: 10.8793\n",
      "Epoch 86/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 13.6565\n",
      "Epoch 00086: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.1778 - val_loss: 11.2029\n",
      "Epoch 87/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 13.1995\n",
      "Epoch 00087: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.9363 - val_loss: 11.0418\n",
      "Epoch 88/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 20.3076\n",
      "Epoch 00088: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.9084 - val_loss: 11.5299\n",
      "Epoch 89/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 24.0253\n",
      "Epoch 00089: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.9179 - val_loss: 11.6823\n",
      "Epoch 90/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 12.2628\n",
      "Epoch 00090: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.9291 - val_loss: 11.1466\n",
      "Epoch 91/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 6.1402\n",
      "Epoch 00091: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.7697 - val_loss: 10.9112\n",
      "Epoch 92/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 6.2383\n",
      "Epoch 00092: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.7387 - val_loss: 11.4355\n",
      "Epoch 93/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 8.0223\n",
      "Epoch 00093: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.6258 - val_loss: 11.6534\n",
      "Epoch 94/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 25.1849\n",
      "Epoch 00094: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.7175 - val_loss: 11.3859\n",
      "Epoch 95/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 9.8637\n",
      "Epoch 00095: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.9052 - val_loss: 10.9754\n",
      "Epoch 96/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 13.1487\n",
      "Epoch 00096: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.4211 - val_loss: 11.6322\n",
      "Epoch 97/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 7.7385\n",
      "Epoch 00097: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.6936 - val_loss: 11.5441\n",
      "Epoch 98/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 10.6581\n",
      "Epoch 00098: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.6741 - val_loss: 10.9621\n",
      "Epoch 99/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 8.6559\n",
      "Epoch 00099: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.4192 - val_loss: 11.6319\n",
      "Epoch 100/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.9274\n",
      "Epoch 00100: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.7292 - val_loss: 11.0125\n",
      "Epoch 101/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 17.3324\n",
      "Epoch 00101: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.5772 - val_loss: 11.4808\n",
      "Epoch 102/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 7.9573\n",
      "Epoch 00102: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.3617 - val_loss: 11.2091\n",
      "Epoch 103/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 11.9320\n",
      "Epoch 00103: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.3987 - val_loss: 11.1969\n",
      "Epoch 104/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 16.6524\n",
      "Epoch 00104: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.5494 - val_loss: 11.2433\n",
      "Epoch 105/150\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 17.1733\n",
      "Epoch 00105: val_loss did not improve from 10.87925\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.5044 - val_loss: 11.3568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00105: early stopping\n",
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efdbc374160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test MSE: 13.950715\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data(nb_days = 28)\n",
    "X, Y = shuffleXY(X, Y)\n",
    "X_train, X_valid, X_test, Y_train, Y_valid, Y_test = split_data()\n",
    "model_month_forward = learn()\n",
    "test_error(model_month_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicton for a month forward: 3.6434593°C degree\n"
     ]
    }
   ],
   "source": [
    "test_array = np.asarray([18, 11, 7.1, 11, 18, 0, 58, 15, 8, 0, 5.2, 15, 0, 59]).reshape(1, -1)\n",
    "print(\"The predicton for a month forward: \" + str(model_month_forward.predict([test_array])[0][0]) + \"°C degree\")\n",
    "#this is for 24th of november"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set your custom nb_days, how many days forward do you want your prediction\n",
    "X, Y = load_data(nb_days = {'insert your number here'})\n",
    "X, Y = shuffleXY(X, Y)\n",
    "X_train, X_valid, X_test, Y_train, Y_valid, Y_test = split_data()\n",
    "model_custom = learn()\n",
    "test_error(model_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.asarray([18, 11, 7.1, 11, 18, 0, 58, 15, 8, 0, 5.2, 15, 0, 59]).reshape(1, -1)\n",
    "print(\"The predicton for custom prediction: \" + str(model_custom.predict([test_array])[0][0]) + \"°C degree\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
